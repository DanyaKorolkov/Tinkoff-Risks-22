{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLLIGPosXyw1"
      },
      "source": [
        "## Альтернативный подход к задачам мультиклассовой классификации:\n",
        "\n",
        "Вместо того, чтобы предсказывать таргет напрямую, мы можем закодировать таргет в двоичном коде и предсказывать каждый бит по отдельности.\n",
        "\n",
        "Тогда нам понадобится всего $~ \\text{log}_2(L + 1)$ классификаторов на L + 1 класс.\n",
        "\n",
        "Попробуем обучить набор таких логрегов и сравнить качество полученного классификатора с мультиномиальной и OvR регрессиями."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJfLpskYXyw4"
      },
      "outputs": [],
      "source": [
        "# импорт базовых библиотек\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set();\n",
        "import scipy.stats as sps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "626_LVHLXyw5"
      },
      "source": [
        "#### Шаг 0: импорт и препроцессинг данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vY6Z-FSRXyw6",
        "outputId": "4d0e29a4-a6ed-4591-a8cf-7270c016737a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wall time: 39.7 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# выгружаем датасет\n",
        "from sklearn.datasets import fetch_openml\n",
        "mnist = fetch_openml(data_id=554) # https://www.openml.org/d/554\n",
        "# генерируем сегментирующую случайную переменую\n",
        "rn = pd.Series(sps.randint.rvs(1, 101, size = len(mnist.data), random_state = 42))\n",
        "# разбиваем на трейн/валидацию/тест\n",
        "X = mnist.data\n",
        "y = mnist.target\n",
        "train_mask, val_mask, test_mask = (rn <= 60), ((rn > 60) & (rn <= 70)), (rn > 70)\n",
        "X_train, y_train, X_test, y_test, X_val, y_val = X[train_mask], y[train_mask], X[test_mask], y[test_mask], X[val_mask], y[val_mask]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wKkluYXpXyw6"
      },
      "outputs": [],
      "source": [
        "# нормируем данные\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_val = scaler.transform(X_val)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhMtbz4AXyw7"
      },
      "source": [
        "#### Шаг 1: учим классификаторы с семинара"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CO5uAclBXyw7"
      },
      "source": [
        "Вообще говоря, мы можем научить классификаторы с базовыми гиперпараметрами -- на семинаре мы видели, что они показывают на нашей задаче неплохое качество, но ведь нет предела совершенству -- давайте подберём какие-нибудь гиперпараметры для логрега (список можно посмотреть тут: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1eKXCxVXyw7"
      },
      "source": [
        "#### Автоматизировать подбор гиперпараметров , как правило, удобнее -- ручной подбор предпочтителен для понимания, что и как влияет на качество моделей, но обычно занимает слишком много времени и сил без каких-либо преимуществ над автоматическим отбором"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XT0uUS7Xyw8"
      },
      "source": [
        "Реализуем функцию grid_search, которая будет делать следующее: принимая обучающую и валидационную выборки, функция обучает набор из классификаторов со всевозможными комбинациями гиперпараметров (предварительно указанных нами для перебора в словаре) и выбирает из них тот, чьё качество по целевой метрике на валидационной выборке оказывается наилучшим."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anoFvX9SXyw8"
      },
      "source": [
        "$\\textbf{Вопрос для размышления:}$ можно ли тут попробовать \"встроить\" защиту от переобучения?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0HT9yu-rXyw8"
      },
      "outputs": [],
      "source": [
        "#реализуем функцию для подбора гиперпараметров модели\n",
        "#для перехода от словаря параметров к списку комбинаций может быть полезен sklearn.model_selection.ParameterGrid\n",
        "def grid_search(X_train,\n",
        "                X_val,\n",
        "                y_train,\n",
        "                y_val,\n",
        "                params_dict):\n",
        "    '''\n",
        "    Функция подбирает гиперпараметры мультиномиальной логитиеской регрессии для получения максимального значения accuracy\n",
        "    на валидационной выборке, принимает:\n",
        "    X_train -- DataFrame независимых переменных на обучающей выборке\n",
        "    X_val -- DataFrame независимых переменных на валидационной выборке\n",
        "    y_train -- Series таргета на обучающей выборке\n",
        "    y_val -- Series таргета на валидационной выборке\n",
        "    params_dict -- словарь гиперпараметров в формате {'paramater_nm':[value_1, value_2, ...]}\n",
        "    '''\n",
        "    ...\n",
        "\n",
        "    return(best_model) #ну или best_parameters, если вдруг так интереснее"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MiMNrMSoXyw9"
      },
      "outputs": [],
      "source": [
        "# тут обучаем свой классификатор -- можно просто .fit() без подбора параметров, можно -- с подбором\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmEeYG1UXyw9"
      },
      "source": [
        "#### Шаг 2: бинаризуем таргет и учим классификаторы"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6FfVLLWQXyw9"
      },
      "outputs": [],
      "source": [
        "def make_binary_predictors(y):\n",
        "    '''\n",
        "    Функция принимает Series y c категориальной переменной и делает DataFrame с [log_2(L+1)] столбцами из 0 и 1\n",
        "\n",
        "    подсказка: в нашем конкретном случае можно переводить десятичное число в двоичное\n",
        "    '''\n",
        "    ...\n",
        "    return(targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fo1oV4-3Xyw9"
      },
      "outputs": [],
      "source": [
        "class BinarisedTargetClassifier():\n",
        "    '''\n",
        "    класс BinarisedTargetClassifier -- мультиклассовый классификатор на основании нескольких бинарных логистических регрессий\n",
        "    '''\n",
        "    def __init__():\n",
        "        ...\n",
        "    def fit(X_train, y_train):\n",
        "        ...\n",
        "    def predict(X):\n",
        "        ...\n",
        "    def predict_score(X): #(без него не построить AUC, но в целом обойтись можно)\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pNQ2mWBXXyw-"
      },
      "outputs": [],
      "source": [
        "#учим созданный классификатор\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "clf_bin = BinarisedTargetClassifier()\n",
        "#обучаем\n",
        "clf_bin.fit(X_train, y_train)\n",
        "#предсказываем класс, считаем accuracy\n",
        "y_pred = clf_bin.predict(X_test)\n",
        "accuracy_bin = accuracy_score(y_test, y_pred)\n",
        "#предсказываем вероятность, считаем AUC\n",
        "score_bin = clf_bin.predict_score(X_test)\n",
        "auc_bin = roc_auc_score(y_test, score_bin, average='macro', multi_class = 'ovr')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9tip9eyXyw-"
      },
      "source": [
        "#### Шаг 3: сравнение качества полученных классификаторов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KaEo3E7xXyw-"
      },
      "outputs": [],
      "source": [
        "accuracy_test = clf.score(X_test, y_test)\n",
        "y_score = clf.predict_proba(X_test)\n",
        "auc_test = roc_auc_score(y_test, y_score, average='macro', multi_class = 'ovr')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7axvTk9qXyw-"
      },
      "outputs": [],
      "source": [
        "res = pd.DataFrame(\n",
        "{'regression_type' : ['sample',...],\n",
        "'accuracy' : [accuracy_test,...],\n",
        "'macro AUC' : [auc_test,...]\n",
        "}\n",
        ")\n",
        "res"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukx6E5DGXyw_"
      },
      "source": [
        "$\\textbf{Вывод}:$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SeAIjLDxXyw_"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}